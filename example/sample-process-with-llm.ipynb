{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b6b6f-761c-4ccc-8ba6-8d2e6058dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19b1ed9c-aea2-455b-9ba7-02fbd648e879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:46:10.257633Z",
     "iopub.status.busy": "2025-11-16T20:46:10.256696Z",
     "iopub.status.idle": "2025-11-16T20:46:10.268049Z",
     "shell.execute_reply": "2025-11-16T20:46:10.267208Z",
     "shell.execute_reply.started": "2025-11-16T20:46:10.257603Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import glob, os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import json\n",
    "import re\n",
    "from json import JSONDecodeError\n",
    "from json_repair import repair_json\n",
    "from openai import OpenAI\n",
    "from islandora7_rest import IslandoraClient\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import layoutparser as lp\n",
    "import time\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Import prompts\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "import prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb6303a-0dab-44c9-b96f-842e5490bd3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:10:11.835828Z",
     "iopub.status.busy": "2025-11-16T20:10:11.835631Z",
     "iopub.status.idle": "2025-11-16T20:10:12.189721Z",
     "shell.execute_reply": "2025-11-16T20:10:12.187638Z",
     "shell.execute_reply.started": "2025-11-16T20:10:11.835809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Islandora client working okay\n"
     ]
    }
   ],
   "source": [
    "# Setup Islandora client\n",
    "isURL = \"https://digital.lib.ku.edu/islandora/rest\"\n",
    "is_client = IslandoraClient(isURL)\n",
    "\n",
    "try:\n",
    "    is_client.solr_query('PID:*root')\n",
    "    print('Islandora client working okay')\n",
    "except Exception as e:\n",
    "    print(f'Islandora client not connecting to REST: {str(e)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ceebd6-b366-478e-925e-cb28757086a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:10:16.253957Z",
     "iopub.status.busy": "2025-11-16T20:10:16.253049Z",
     "iopub.status.idle": "2025-11-16T20:10:17.598147Z",
     "shell.execute_reply": "2025-11-16T20:10:17.597381Z",
     "shell.execute_reply.started": "2025-11-16T20:10:16.253926Z"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter LLM key UzfXwCIvp6q0ZsxjH3NaBsp5JxfHcmgC\n"
     ]
    }
   ],
   "source": [
    "key = input('Enter LLM key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed8a86f1-7ff9-4ef0-a196-f7a719ffad80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:10:21.783097Z",
     "iopub.status.busy": "2025-11-16T20:10:21.782514Z",
     "iopub.status.idle": "2025-11-16T20:10:24.850458Z",
     "shell.execute_reply": "2025-11-16T20:10:24.849132Z",
     "shell.execute_reply.started": "2025-11-16T20:10:21.783069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM connection successful\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=key, base_url=\"https://ellm.nrp-nautilus.io/v1\", max_retries=0)\n",
    "llm_model = 'glm-v'\n",
    "\n",
    "# Test LLM connection\n",
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=llm_model,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"\"},\n",
    "                 {\"role\": \"user\", \"content\": \"Just checking to see if you're awake.\"}])\n",
    "    print('LLM connection successful')\n",
    "except Exception as e:\n",
    "    print(f'LLM connection failed: {str(e)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c56edf7-a8af-45d2-ba23-e46dba33d0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:10:24.857275Z",
     "iopub.status.busy": "2025-11-16T20:10:24.856922Z",
     "iopub.status.idle": "2025-11-16T20:10:53.994827Z",
     "shell.execute_reply": "2025-11-16T20:10:53.994507Z",
     "shell.execute_reply.started": "2025-11-16T20:10:24.857249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading layoutparser model...\n",
      "Layoutparser model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load layoutparser model\n",
    "def load_newspaper_navigator():\n",
    "    try:\n",
    "        config_path = 'lp://NewspaperNavigator/faster_rcnn_R_50_FPN_3x/config'\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        return lp.models.Detectron2LayoutModel(\n",
    "            config_path=config_path,\n",
    "             extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.5], # limit confidence score\n",
    "             device=device\n",
    "            )\n",
    "    except ValueError:\n",
    "        # Load Newspaper Navigator model from local files\n",
    "        # have had trouble with downloading in some cases\n",
    "        model_dir = os.path.expanduser(\"~/newspaper_navigator_model\")\n",
    "        config_path = os.path.join(model_dir, \"config.yml\")\n",
    "        model_path = os.path.join(model_dir, \"model_final.pth\")\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        if not (os.path.exists(config_path) and os.path.exists(model_path)):\n",
    "            raise FileNotFoundError(f\"Model files not found in {model_dir}. Run the download script first.\")\n",
    "        \n",
    "        return lp.models.Detectron2LayoutModel(\n",
    "            config_path=config_path,\n",
    "            model_path=model_path,\n",
    "            extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.5], # limit confidence score\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "print(\"Loading layoutparser model...\")\n",
    "try:\n",
    "    lp_model = load_newspaper_navigator()\n",
    "    print(\"Layoutparser model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load layoutparser model: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "287257c3-6cb9-4d50-a89c-dbbd9c0959b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:10:53.995489Z",
     "iopub.status.busy": "2025-11-16T20:10:53.995401Z",
     "iopub.status.idle": "2025-11-16T20:10:53.998694Z",
     "shell.execute_reply": "2025-11-16T20:10:53.998414Z",
     "shell.execute_reply.started": "2025-11-16T20:10:53.995480Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_lp(results):\n",
    "    # for items with matching bounding boxes, return only the highest confidence\n",
    "    max_items = {}\n",
    "    for item in results:\n",
    "        key = (item['x_1'], item['y_1'], item['x_2'], item['y_2'])\n",
    "        if key not in max_items or item['score'] > max_items[key]['score']:\n",
    "            max_items[key] = item\n",
    "    return list(max_items.values())\n",
    "\n",
    "def run_lp(pid, identifier, lp=True):\n",
    "\n",
    "    image = get_image(pid)\n",
    "    results = []\n",
    "    # START - comment out to skip layoutparser (2 of 2)\n",
    "    if lp:\n",
    "        image_for_lp = np.array(image)\n",
    "        layout = lp_model.detect(image_for_lp)\n",
    "    \n",
    "        for l in layout:\n",
    "            results.append({\n",
    "                    'x_1': l.block.x_1, 'y_1': l.block.y_1, 'x_2': l.block.x_2, 'y_2': l.block.y_2,\n",
    "                    'score': l.score, 'type': l.type,\n",
    "                    'identifier': identifier, 'pid': pid,\n",
    "                    })\n",
    "    \n",
    "        results = filter_lp(results)\n",
    "        print(f'Layout Parser complete with {len(results)} items')\n",
    "    # END - comment out to skip layoutparser\n",
    "    return results, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6de3c5-76a3-4e76-bfd7-06c92d05515c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:10:53.999792Z",
     "iopub.status.busy": "2025-11-16T20:10:53.999720Z",
     "iopub.status.idle": "2025-11-16T20:10:54.012818Z",
     "shell.execute_reply": "2025-11-16T20:10:54.012561Z",
     "shell.execute_reply.started": "2025-11-16T20:10:53.999785Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_image(pid, max_retries=5):\n",
    "\n",
    "    url = f'https://digital.lib.ku.edu/islandora/object/{pid}/datastream/OBJ/view'\n",
    "\n",
    "    # Retry loop for GET request\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=60)\n",
    "            response.raise_for_status()\n",
    "            image = Image.open(io.BytesIO(response.content))\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            return image\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:  # Last attempt\n",
    "                raise\n",
    "            time.sleep(3 ** attempt)  # Exponential backoff: 1s, 3s, 9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a31bc4-a45b-4933-9f2a-1629f21096f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:10:54.013278Z",
     "iopub.status.busy": "2025-11-16T20:10:54.013204Z",
     "iopub.status.idle": "2025-11-16T20:10:54.017588Z",
     "shell.execute_reply": "2025-11-16T20:10:54.017354Z",
     "shell.execute_reply.started": "2025-11-16T20:10:54.013270Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_dates(s):\n",
    "    s = s.replace('udk_','').replace('udk-','')\n",
    "    try:\n",
    "        if len(s.split('_')) == 2:\n",
    "            start_str, end_str = s.split('_')\n",
    "            start = datetime.strptime(start_str, '%m-%d-%Y')\n",
    "            end = datetime.strptime(end_str, '%m-%d-%Y')\n",
    "            return start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d')\n",
    "        elif len(s.split('_')) == 6:\n",
    "            start_m, start_d, start_y, end_m, end_d, end_y = s.split('_')\n",
    "            start = datetime(int(start_y), int(start_m), int(start_d))\n",
    "            end = datetime(int(end_y), int(end_m), int(end_d))\n",
    "            return start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d')\n",
    "        elif len(s.split('-')) == 6:\n",
    "            start_m, start_d, start_y, end_m, end_d, end_y = s.split('-')\n",
    "            start = datetime(int(start_y), int(start_m), int(start_d))\n",
    "            end = datetime(int(end_y), int(end_m), int(end_d))\n",
    "            return start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d')\n",
    "        elif '_to_' in s:\n",
    "            parts = s.split('_to_')\n",
    "            start = datetime.strptime(parts[0].replace('_', '/'), '%m/%d/%Y')\n",
    "            end = datetime.strptime(parts[1].replace('_', '/'), '%m/%d/%Y')\n",
    "            return start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d')\n",
    "        elif len(s.split('_')) == 4:\n",
    "            start_str, end_m, end_d, end_y = s.split('_')\n",
    "            start_m, start_d, start_y = start_str.split('-')\n",
    "            start = datetime(int(start_y), int(start_m), int(start_d))\n",
    "            end = datetime(int(end_y), int(end_m), int(end_d))\n",
    "            return start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            _, start_str, end_str = s.split('-')\n",
    "            start = datetime.strptime(start_str, '%Y%m%d')\n",
    "            end = datetime.strptime(end_str, '%Y%m%d')\n",
    "            return start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d')\n",
    "    except ValueError as e:\n",
    "        print(f'Unknown date format: {s}, error: {str(e)}')\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5583c790-061b-4873-abd6-2b7e6bef4ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:10:54.017963Z",
     "iopub.status.busy": "2025-11-16T20:10:54.017900Z",
     "iopub.status.idle": "2025-11-16T20:10:54.021077Z",
     "shell.execute_reply": "2025-11-16T20:10:54.020843Z",
     "shell.execute_reply.started": "2025-11-16T20:10:54.017956Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_img(image):\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format='JPEG', quality=95, optimize=True, subsampling=0)\n",
    "    buffer.seek(0)\n",
    "    return base64.b64encode(buffer.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74ed90a7-caef-423b-b2c3-000268f080a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:10:54.021577Z",
     "iopub.status.busy": "2025-11-16T20:10:54.021467Z",
     "iopub.status.idle": "2025-11-16T20:10:54.024556Z",
     "shell.execute_reply": "2025-11-16T20:10:54.024341Z",
     "shell.execute_reply.started": "2025-11-16T20:10:54.021567Z"
    }
   },
   "outputs": [],
   "source": [
    "def crop_and_encode(image, header=False, coords=None):\n",
    "    if header:\n",
    "        w, h = image.size\n",
    "        img = image\n",
    "    elif coords:\n",
    "        img = image.crop((coords['x_1'], coords['y_1'], coords['x_2'], coords['y_2']))\n",
    "    else:\n",
    "        img = image\n",
    "    if img.mode in ('RGBA', 'LA', 'P'):\n",
    "        img = img.convert('RGB')\n",
    "\n",
    "    max_file_size = 3355443  # 3.2MB\n",
    "    max_size = 4000 # pixel length\n",
    "\n",
    "    # Try original image first\n",
    "    image_encode = encode_img(img)\n",
    "    image_encode_size = len(image_encode)\n",
    "\n",
    "    if image_encode_size <= max_file_size:\n",
    "        print(f\"Image size OK: {image_encode_size / (1024 * 1024):.2f}MB\")\n",
    "        return image_encode\n",
    "\n",
    "    while max_size >= 100:\n",
    "        # Calculate new dimensions\n",
    "        width, height = img.size\n",
    "        scale = max_size / max(width, height)\n",
    "\n",
    "        if scale >= 1:\n",
    "            resized_img = img\n",
    "        else:\n",
    "            new_width = int(width * scale)\n",
    "            new_height = int(height * scale)\n",
    "            resized_img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "\n",
    "        image_encode = encode_img(resized_img)\n",
    "        print(f'Resized image: {len(image_encode)/(1024*1024):.2f}MB')\n",
    "\n",
    "        # Check size\n",
    "        if len(image_encode) <= max_file_size:\n",
    "            return image_encode\n",
    "\n",
    "        # Calculate next size\n",
    "        size_ratio = max_file_size / len(image_encode)\n",
    "        max_size = int(max_size * (size_ratio ** 0.5) * 0.93)\n",
    "\n",
    "    return image_encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33cc87e8-56b9-4348-a9df-819ba16bf8de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:10:54.025090Z",
     "iopub.status.busy": "2025-11-16T20:10:54.024980Z",
     "iopub.status.idle": "2025-11-16T20:10:54.028832Z",
     "shell.execute_reply": "2025-11-16T20:10:54.028632Z",
     "shell.execute_reply.started": "2025-11-16T20:10:54.025081Z"
    }
   },
   "outputs": [],
   "source": [
    "def fix_json_values(text):\n",
    "    try:\n",
    "        text = repair_json(text)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        # Fallback to manual fixes if json-repair fails\n",
    "        logger.debug(f\"json-repair failed: {e}, trying manual fixes\")\n",
    "        text = re.sub(r'(\"[^\"]+\"):\\s*([0-9]+[A-Za-z][A-Za-z0-9]*)', r'\\1: \"\\2\"', text)\n",
    "        text = re.sub(r',(\\s*[}\\]])', r'\\1', text)\n",
    "        return text\n",
    "\n",
    "def decode_message(message):\n",
    "    try:\n",
    "        text = message.content[0].text\n",
    "    except:\n",
    "        text = message\n",
    "\n",
    "    to_strip = [r'json\\n', '<|end_of_box|>', '<|start_of_box|>','<|begin_of_box|>',\n",
    "                '<think>', '</think>', '```json', '```']\n",
    "\n",
    "    for t in to_strip:\n",
    "        try:\n",
    "            text = text.strip().replace(t, '')\n",
    "        except (IndexError, AttributeError):\n",
    "            continue\n",
    "\n",
    "    cleaned = text.replace('\\n', '').strip()\n",
    "\n",
    "    if cleaned and cleaned[0] != '{':\n",
    "        cleaned = '{' + cleaned\n",
    "    if cleaned and not cleaned.endswith('}'):\n",
    "        cleaned = cleaned + '}'\n",
    "\n",
    "    for i, char in enumerate(cleaned):\n",
    "        if char == '{':\n",
    "            bracket_count = 0\n",
    "            for j in range(i, len(cleaned)):\n",
    "                if cleaned[j] == '{':\n",
    "                    bracket_count += 1\n",
    "                elif cleaned[j] == '}':\n",
    "                    bracket_count -= 1\n",
    "                    if bracket_count == 0:\n",
    "                        candidate = cleaned[i:j+1]\n",
    "\n",
    "                        try:\n",
    "                            data = json.loads(candidate)\n",
    "                            return data\n",
    "                        except json.JSONDecodeError as e:\n",
    "                            try:\n",
    "                                data = json.loads(fix_json_values(candidate))\n",
    "                                return data\n",
    "                            except json.JSONDecodeError as e:\n",
    "                                print(f'JSON decode error at position {e.pos}: {e.msg}')\n",
    "                                print(f'Problematic text: {candidate[max(0, e.pos-50):e.pos+50]}')\n",
    "\n",
    "                                return {\"error\": \"Badly formed JSON response\"}\n",
    "\n",
    "    print(f'JSON decode error: {cleaned[:200]}')\n",
    "    return {\"error\":\"Badly formed JSON response\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d78d032-94bb-4ad1-a44e-e59c63ea29d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:10:54.029301Z",
     "iopub.status.busy": "2025-11-16T20:10:54.029220Z",
     "iopub.status.idle": "2025-11-16T20:10:54.034109Z",
     "shell.execute_reply": "2025-11-16T20:10:54.033865Z",
     "shell.execute_reply.started": "2025-11-16T20:10:54.029293Z"
    }
   },
   "outputs": [],
   "source": [
    "def llm_query(pid, identifier, date, image, header=False, coords=None, max_retries=5):\n",
    "    \"\"\"LLM query with retry logic and rate limiting\"\"\"\n",
    "\n",
    "    # Determine prompt and image based on query type\n",
    "    if header:\n",
    "        img_enc = crop_and_encode(image, header=True)\n",
    "        url = f\"data:image/jpeg;base64,{img_enc}\"\n",
    "        sys_prompt = prompts.page_prompt()\n",
    "    elif coords:\n",
    "        if coords[0] == 'ads':\n",
    "            sys_prompt = prompts.ad_prompt()\n",
    "        else:\n",
    "            sys_prompt = prompts.ed_comics_prompt()\n",
    "        img_enc = crop_and_encode(image, coords=coords[1])\n",
    "        url = f\"data:image/jpeg;base64,{img_enc}\"\n",
    "    else:\n",
    "\n",
    "        # url = f'https://digital.lib.ku.edu/islandora/object/{pid}/datastream/OBJ/view'\n",
    "        # alt method of sending pre-encoded image\n",
    "        img_enc = crop_and_encode(image)\n",
    "        url = f\"data:image/jpeg;base64,{img_enc}\"\n",
    "        sys_prompt = prompts.item_prompt()\n",
    "\n",
    "    text = \"\"\"Process this image according to system directions.\"\"\"\n",
    "    if date:\n",
    "        text += f\"Likely date range for this item is {date}.\"\n",
    "\n",
    "    # Retry loop with exponential backoff\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=llm_model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [{\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": text\n",
    "                        },\n",
    "                        {\"type\": \"image_url\",\n",
    "                         \"image_url\": {\"url\": url}}]\n",
    "                    },\n",
    "                    {\"role\": \"assistant\", \"content\": \"{\"}\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            msg = completion.choices[0].message.content\n",
    "\n",
    "            # Add small delay between successful calls to avoid hammering LLM\n",
    "            # time.sleep(0.5)\n",
    "            # test for valid json\n",
    "            try:\n",
    "                result = json.loads(msg)\n",
    "                result['model'] = completion.model\n",
    "                return result\n",
    "            except JSONDecodeError:\n",
    "                decoded_msg = decode_message(msg)\n",
    "                decoded_msg['model'] = completion.model\n",
    "                return decoded_msg\n",
    "\n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            base_delay = 2\n",
    "\n",
    "            if attempt < max_retries - 1:\n",
    "                delay = base_delay * (2 ** attempt) + random.uniform(0, 1)\n",
    "                print(f\"LLM error for {pid} (attempt {attempt+1}/{max_retries}), retrying in {delay:.1f}s: {error_str}\")\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "            # Non-retryable error or out of retries\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f602209a-285e-4647-ba1b-ffa2d5c8ebdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:10:54.035578Z",
     "iopub.status.busy": "2025-11-16T20:10:54.035493Z",
     "iopub.status.idle": "2025-11-16T20:10:59.916600Z",
     "shell.execute_reply": "2025-11-16T20:10:59.915687Z",
     "shell.execute_reply.started": "2025-11-16T20:10:54.035571Z"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Path to data directory:  /Users/e996w533/Documents/collections/udk-microfilm/scripts/workflow/nrp-jobs/production_1/data\n"
     ]
    }
   ],
   "source": [
    "# Ensure output directory exists\n",
    "outdir = input('Path to data directory: ')\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a09cfa2c-eacc-4a2e-89b9-a9388a260d83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:49:26.414922Z",
     "iopub.status.busy": "2025-11-16T20:49:26.412797Z",
     "iopub.status.idle": "2025-11-16T20:49:26.427844Z",
     "shell.execute_reply": "2025-11-16T20:49:26.427069Z",
     "shell.execute_reply.started": "2025-11-16T20:49:26.414825Z"
    }
   },
   "outputs": [],
   "source": [
    "output_files = {\n",
    "    'lp_items': '{}/lp_items_{}_{}.csv',\n",
    "    'pages': '{}/pages_{}_{}.csv',\n",
    "    'llm_items': '{}/llm_items_{}_{}.csv',\n",
    "    'ads': '{}/ads_{}_{}_{}.csv',\n",
    "    'ed_comics': '{}/ed_comics_{}_{}_{}.csv',\n",
    "    'errors': '{}/errors_{}_{}_{}.csv',\n",
    "}\n",
    "\n",
    "def save_results(num='16'):\n",
    "    \"\"\"Save current results to CSV\"\"\"\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S%f')\n",
    "\n",
    "    for data in [(lp_results, 'lp_items'),(page_results,'pages'),\n",
    "        (llm_item_results,'llm_items'),(ad_results,'ads'),\n",
    "        (edc_results,'ed_comics'),(error_results,'errors')]:\n",
    "        if data[0]:\n",
    "            fn = output_files[data[1]].format(outdir, timestamp, num)\n",
    "            pd.DataFrame(data[0]).to_csv(fn, index=False)\n",
    "            print(f\"Saved {len(data[0])} {fn}\")\n",
    "\n",
    "    print(f\"Results saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e00f99d-3840-4202-baed-c44064986ad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:49:44.960633Z",
     "iopub.status.busy": "2025-11-16T20:49:44.959710Z",
     "iopub.status.idle": "2025-11-16T20:49:44.968281Z",
     "shell.execute_reply": "2025-11-16T20:49:44.967182Z",
     "shell.execute_reply.started": "2025-11-16T20:49:44.960600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize result lists\n",
    "lp_results = []\n",
    "page_results = []\n",
    "llm_item_results = []\n",
    "ad_results = []\n",
    "edc_results = []\n",
    "error_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bc6d09f-de33-425b-a692-b964383d9ea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:49:45.755053Z",
     "iopub.status.busy": "2025-11-16T20:49:45.754433Z",
     "iopub.status.idle": "2025-11-16T20:49:45.762321Z",
     "shell.execute_reply": "2025-11-16T20:49:45.760129Z",
     "shell.execute_reply.started": "2025-11-16T20:49:45.755023Z"
    }
   },
   "outputs": [],
   "source": [
    "# pid and identifier are both required\n",
    "# for testing, enter as a list of tuples: [(pid, identifier)]\n",
    "tasks = [\n",
    " ('ku-udk:200538',),\n",
    " ('ku-udk:199673',),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "675cb7bb-7706-4027-a810-e6148802a8f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:49:46.894005Z",
     "iopub.status.busy": "2025-11-16T20:49:46.893453Z",
     "iopub.status.idle": "2025-11-16T20:51:07.378648Z",
     "shell.execute_reply": "2025-11-16T20:51:07.376571Z",
     "shell.execute_reply.started": "2025-11-16T20:49:46.893975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24a2d4771224175abe019b719745860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image retrieved successfully\n",
      "Resized image: 6.89MB\n",
      "Resized image: 3.04MB\n",
      "Items processed successfully\n",
      "Successfully processed ku-udk:200538\n",
      "  -- Current count: 36 llm_items\n",
      "Image retrieved successfully\n",
      "Resized image: 6.84MB\n",
      "Resized image: 3.04MB\n",
      "Items processed successfully\n",
      "Successfully processed ku-udk:199673\n",
      "  -- Current count: 55 llm_items\n"
     ]
    }
   ],
   "source": [
    "lp_process = False\n",
    "try:\n",
    "    df_items.shape\n",
    "except:\n",
    "    df_items = pd.DataFrame(columns=['pid'])\n",
    "\n",
    "for task in tqdm(tasks):\n",
    "    # print(task)\n",
    "    res = is_client.solr_query(f'PID:\"{task[0]}\"', fl=['PID','mods_identifier_local_displayLabel_ms'])\n",
    "    ident = res['response']['docs'][0]['mods_identifier_local_displayLabel_ms'][0]\n",
    "\n",
    "    pid = task[0]\n",
    "    # identifier = task[1]\n",
    "    identifier = ident\n",
    "    \n",
    "    if pid in df_items.pid.unique():\n",
    "        continue\n",
    "    try:\n",
    "        # layout parser\n",
    "        lp_data, image = run_lp(pid, identifier, lp=lp_process)\n",
    "        print(\"Image retrieved successfully\")\n",
    "        consecutive_errors = 0\n",
    "    \n",
    "        # Store results\n",
    "        if lp_data:\n",
    "            lp_results.extend(lp_data)\n",
    "            print(\"LP data added\")\n",
    "    \n",
    "    except Exception as e:\n",
    "                print(e)\n",
    "                # consecutive_errors = log_error(pid, identifier, e, task, error_count, consecutive_errors)\n",
    "                if consecutive_errors >= 10:\n",
    "                    print(\"Too many consecutive errors, exiting\")\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "    # llm queries\n",
    "    try:\n",
    "        # LLM data\n",
    "        start_date, end_date = parse_dates(identifier.split('/')[0])\n",
    "        date_range = f\"{start_date} to {end_date}\" if start_date and end_date else \"unknown\"\n",
    "\n",
    "        # # START - comment out to skip page-level LLM (1 of 1)\n",
    "        # # Page metadata - header\n",
    "        # page_query = llm_query(pid, identifier, date_range, image, header=True)\n",
    "        # page_results.append({'pid': pid, \"identifier\": identifier, **page_query})\n",
    "        # print(\"Page processed successfully\")\n",
    "        # # END - comment out to skip page-level LLM (1 of 1)\n",
    "\n",
    "        # START - comment out to skip item-level LLM (1 of 1)\n",
    "        # LLM items\n",
    "        llm_item_query = llm_query(pid, identifier, date_range, image)\n",
    "        if len(llm_item_query.get('items', [])) > 0:\n",
    "            for item in llm_item_query['items']:\n",
    "                llm_item_results.append({'pid': pid, \"identifier\": identifier, **item})\n",
    "        print(\"Items processed successfully\")\n",
    "        # END - comment out to skip item-level LLM\n",
    "\n",
    "        # # START - comment out to skip ads via LLM (requires layoutparser) (1 of 1)\n",
    "        # # # Ads\n",
    "        # lp_ads = [d for d in lp_data if d['type'] == 6]\n",
    "        # xy_coords = ['x_1', 'x_2', 'y_1', 'y_2']\n",
    "        \n",
    "        # if len(lp_ads) == 0:\n",
    "        #     ad_results.append({'pid': pid, 'identifier': identifier, 'error': 'No ads found by LLM'})\n",
    "        # else:\n",
    "        #     for ad_dict in lp_ads:\n",
    "        #         ad_coords = {k: ad_dict[k] for k in xy_coords if k in ad_dict}\n",
    "        #         ad_query = llm_query(pid, identifier, date_range, image, coords=('ads',ad_coords))\n",
    "        #         ad_results.append({'pid': pid, \"identifier\": identifier, **ad_coords, **ad_query})\n",
    "        # print(\"Ads processed successfully\")\n",
    "        # # END - comment out to skip ads\n",
    "\n",
    "        # # START - comment out to skip editorial comics via LLM (requires layoutparser) (1 of 1)\n",
    "        # # editorial comics\n",
    "\n",
    "        # # OPTION A - set lp_edc from existing lp_df\n",
    "        # # # lp_data = lp_df[(lp_df.pid==pid) & (lp_df.type==4)]\n",
    "        # # # lp_edc = lp_data.to_dict('records')\n",
    "        # #\n",
    "        # # # OPTION B - set lp_edc from just-run lp_data\n",
    "        # lp_edc = [d for d in lp_data if d['type'] == 4]\n",
    "        # xy_coords = ['x_1', 'x_2', 'y_1', 'y_2']\n",
    "        \n",
    "        # if len(lp_edc) == 0:\n",
    "        #     pass\n",
    "        #     # edc_results.append({'pid': pid, 'identifier': identifier, 'error': 'No editorial comics found by LP'})\n",
    "        # else:\n",
    "        #     for edc_dict in lp_edc:\n",
    "        #         edc_coords = {k: edc_dict[k] for k in xy_coords if k in edc_dict}\n",
    "        #         edc_query = llm_query(pid, identifier, date_range, image, coords=('edc',edc_coords))\n",
    "        #         edc_results.append({'pid': pid, \"identifier\": identifier, **edc_coords, **edc_query})\n",
    "        #     print(\"Editorial cartoons processed successfully\")\n",
    "        # # END - comment out to skip editorial comics\n",
    "\n",
    "        consecutive_errors = 0  # Reset error counter on success\n",
    "        print(f\"Successfully processed {pid}\")\n",
    "\n",
    "        # optional logging to keep running count\n",
    "        for data in [(lp_results, 'lp_items'),(page_results,'pages'),\n",
    "            (llm_item_results,'llm_items'),(ad_results,'ads'),\n",
    "            (edc_results,'ed_comics'),(error_results,'errors')]:\n",
    "            if data[0]:\n",
    "                print(f\"  -- Current count: {len(data[0])} {data[1]}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # consecutive_errors = log_error(pid, identifier, e, task, error_count, consecutive_errors)\n",
    "        print(e)\n",
    "        if consecutive_errors >= 10:\n",
    "            print(\"Too many consecutive errors, exiting\")\n",
    "            break\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fa97178-aecc-4874-b6b7-047b894e4cdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:51:19.070160Z",
     "iopub.status.busy": "2025-11-16T20:51:19.069570Z",
     "iopub.status.idle": "2025-11-16T20:51:19.095612Z",
     "shell.execute_reply": "2025-11-16T20:51:19.094730Z",
     "shell.execute_reply.started": "2025-11-16T20:51:19.070126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check items\n",
    "page_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "527f50b8-1108-4a0d-bf3a-482536860f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:51:21.605097Z",
     "iopub.status.busy": "2025-11-16T20:51:21.604378Z",
     "iopub.status.idle": "2025-11-16T20:51:21.628641Z",
     "shell.execute_reply": "2025-11-16T20:51:21.627793Z",
     "shell.execute_reply.started": "2025-11-16T20:51:21.605066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 55 /Users/e996w533/Documents/collections/udk-microfilm/scripts/workflow/nrp-jobs/production_1/data/llm_items_20251116_145121608180_17.csv\n",
      "Results saved successfully\n"
     ]
    }
   ],
   "source": [
    "save_results(num='17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dd3b1a-6581-4e2b-933f-e658f2c2e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review as needed\n",
    "df_items = pd.DataFrame(llm_item_results)\n",
    "df_items.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a651465-a746-4f28-b25d-02cb8b9ef07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.pid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b002e9d-151d-4a1b-8268-d5d3716675d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.to_csv('../../production_1/data/merged_data_llm_14.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163133e4-ebce-4834-a8d6-cb2b66cec0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
